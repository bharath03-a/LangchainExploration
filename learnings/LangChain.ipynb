{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So choosing a frame work is key in bulding LLM Gen AI applications and also building AI agents.\n",
    "\n",
    "Among those we a few which are `LlamaIndex` and `Langchain`.\n",
    "\n",
    "with usecases like prompts, document loaders, vector stores.\n",
    "\n",
    "Langchain operates on a high-level of abstraction\n",
    "\n",
    "RAG - https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"Starting\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.environ.get(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama, OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    model = \"llama3.2:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='नमस्ते, आप कैसे हैं?' additional_kwargs={} response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-01-31T07:23:08.509169Z', 'done': True, 'done_reason': 'stop', 'total_duration': 535678000, 'load_duration': 31683500, 'prompt_eval_count': 55, 'prompt_eval_duration': 186000000, 'eval_count': 13, 'eval_duration': 316000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-2fd3b78e-1a67-4edd-8644-7268528fbfd5-0' usage_metadata={'input_tokens': 55, 'output_tokens': 13, 'total_tokens': 68}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a translator from English to Hindi. Translate the following from Englisht to Hindi. Just provide the translation.\"),\n",
    "    HumanMessage(\"Hello, how are you?\")\n",
    "]\n",
    "\n",
    "@traceable\n",
    "def run_llm():\n",
    "    return model.invoke(messages)\n",
    "\n",
    "print(run_llm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For some reason langsmith is not working for me, weirdly enough..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-01-31T07:23:13.636723Z', 'done': True, 'done_reason': 'stop', 'total_duration': 218851750, 'load_duration': 10784541, 'prompt_eval_count': 26, 'prompt_eval_duration': 26000000, 'eval_count': 8, 'eval_duration': 181000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-64d7b0ac-8f51-4662-85bd-55daeb28a77e-0', usage_metadata={'input_tokens': 26, 'output_tokens': 8, 'total_tokens': 34})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "न|म|स|्त|े,| आप| क|ैस|े| ह|ैं|?||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applications",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
